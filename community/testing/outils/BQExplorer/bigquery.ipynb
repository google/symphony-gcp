{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import src.table_stats\n",
    "reload(src.table_stats)\n",
    "\n",
    "from src.table_stats import print_stats\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Set maximum width for table view\n",
    "pd.set_option('max_colwidth', 60)\n",
    "# Set maximum rows for table view\n",
    "pd.set_option('display.max_rows',200)\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "DATA_FOLDER = Path(os.getenv(\"WORKDIR\")).joinpath(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5102875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure query by run id\n",
    "\n",
    "PROJECT_ID = \"symphony-dev-2\"\n",
    "DATASET_ID = \"log_dataset_default\"\n",
    "TABLE_ID = \"logs-2\"\n",
    "RUN_ID = \"test-5000-iter-3\"\n",
    "# RUN_ID = \"test-3000-iter-2\"\n",
    "# RUN_ID = \"test-fail-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT DISTINCT run from `{project}.{dataset}.{table}`\n",
    "\"\"\".format(\n",
    "    project = PROJECT_ID,\n",
    "    dataset = DATASET_ID,\n",
    "    table = TABLE_ID,\n",
    "    run_id = RUN_ID\n",
    ")\n",
    "\n",
    "query_job = client.query(QUERY)\n",
    "rows = query_job.result()\n",
    "df = rows.to_dataframe()\n",
    "runs = df[\"run\"].to_list()\n",
    "\n",
    "RUN_ID in runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff01960",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"\"\"\n",
    "SELECT * from `{project}.{dataset}.{table}`\n",
    "WHERE run = \"{run_id}\"\n",
    "ORDER BY time DESC\n",
    "-- LIMIT 1000 \n",
    "-- Optionally limit the query when dealing with too big datasets...\n",
    "\"\"\".format(\n",
    "    project = PROJECT_ID,\n",
    "    dataset = DATASET_ID,\n",
    "    table = TABLE_ID,\n",
    "    run_id = RUN_ID\n",
    ")\n",
    "\n",
    "query_job = client.query(QUERY)\n",
    "rows = query_job.result()\n",
    "df = rows.to_dataframe()\n",
    "\n",
    "# Parse detail json string\n",
    "df.detail = df.detail.apply(lambda x: json.loads(x) if x is not None else None)\n",
    "\n",
    "# Sort by time\n",
    "df = df.set_index(\"time\").sort_index().reset_index()\n",
    "\n",
    "# Optionally identify when grr changed\n",
    "df[\"grr_shift_out\"] = df[df.event == \"cli:grr_out\"].detail != df[df.event == \"cli:grr_out\"].shift().detail\n",
    "df[\"grr_shift_in\"] = df[df.event == \"cli:grr_in\"].detail != df[df.event == \"cli:grr_in\"].shift().detail\n",
    "\n",
    "print_stats(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b64b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: Backpropagate grs_in requestId\n",
    "TODO: Backpropagate grs_out machineId \n",
    "TODO: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUEST_TIMESTAMP = None; RETURN_TIMESTAMP = None\n",
    "\n",
    "REQUEST_TIMESTAMP = \"2025-09-04T12:03:37+00:00\"\n",
    "RETURN_TIMESTAMP = \"2025-09-04T12:38:26+00:00\"\n",
    "\n",
    "REQUEST_TIMESTAMP = datetime.datetime.fromisoformat(REQUEST_TIMESTAMP).astimezone(datetime.UTC)\n",
    "RETURN_TIMESTAMP = datetime.datetime.fromisoformat(RETURN_TIMESTAMP).astimezone(datetime.UTC)\n",
    "\n",
    "\n",
    "test_folder = DATA_FOLDER.joinpath(RUN_ID)\n",
    "\n",
    "cloud_hosts_path = test_folder.joinpath(\"cloud_hosts.csv\")\n",
    "\n",
    "cloud_hosts = None\n",
    "if os.path.isfile(cloud_hosts_path):\n",
    "    cloud_hosts_df = pd.read_csv(\n",
    "        cloud_hosts_path,\n",
    "        index_col=0,\n",
    "        converters={\n",
    "            \"releaseTime\": datetime.datetime.fromisoformat,\n",
    "            \"launchTime\": datetime.datetime.fromisoformat\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d86ba2",
   "metadata": {},
   "source": [
    "# Pod Parsing and back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596377b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add preemption analysis with `dfc_pivot_preempted` and `cloud_hosts`\n",
    "\n",
    "# Copy dataframe\n",
    "dfc = df.copy(deep=True)\n",
    "\n",
    "# Filter pertinent events\n",
    "dfc = dfc[\n",
    "    dfc.event.isin([\n",
    "            \"cli:rm_out\",\n",
    "            \"pod:create\",\n",
    "            \"pod:scheduled\",\n",
    "            \"container:started\",\n",
    "            \"node:preempted\",\n",
    "            \"cli:grs_out\",\n",
    "            \"cli:rrm_in\",\n",
    "            \"pod:delete\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "# ========= Parse Node Preemption =========\n",
    "\n",
    "# This transforms the `node:preempted` into multiple `pod:node_preempted` for\n",
    "# all pods that have been scheduled to the node before its preemption.\n",
    "# This is latter used to remove lines from the pivoted table\n",
    "\n",
    "def parse_preemption(row):\n",
    "    row.pod = df[\n",
    "        np.logical_and.reduce([\n",
    "            df.event == \"pod:scheduled\",\n",
    "            df.node == row.node,\n",
    "            df.time <= row.time\n",
    "        ])\n",
    "    ].pod.to_list()\n",
    "    row.event = \"pod:node_preempted\"\n",
    "    return row\n",
    "\n",
    "\n",
    "dfc = pd.concat([\n",
    "    dfc.loc[~(dfc.event == \"node:preempted\")],\n",
    "    dfc[dfc.event == \"node:preempted\"].apply(\n",
    "        parse_preemption, axis=1\n",
    "    ).explode(\"pod\")\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# ========= Parse RM =========\n",
    "\n",
    "# This transforms a single cli:rm_out into multiple pod:rm\n",
    "# extracting the pod name\n",
    "\n",
    "def parse_rm_out(row):\n",
    "    # Get associated pods\n",
    "    row.pod = dfc[dfc.sym_request == row.detail[\"payload\"][\"requestId\"]].pod.to_list()\n",
    "    # Change event name\n",
    "    row.event = \"cli:rm\"\n",
    "    return row\n",
    "\n",
    "dfc = pd.concat([\n",
    "    dfc.loc[~(dfc.event == \"cli:rm_out\")],\n",
    "    dfc[dfc.event == \"cli:rm_out\"].apply(\n",
    "        parse_rm_out, axis=1\n",
    "    ).explode(\"pod\")\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# ========= Parse RRM =========\n",
    "\n",
    "# This transforms a single cli:rrm_in into multiple pod:rrm\n",
    "# extracting the pod name\n",
    "\n",
    "def parse_rrm_in(row):\n",
    "    # Get pod names\n",
    "    row.pod = [machine[\"name\"] for machine in row.detail[\"payload\"][\"machines\"]]\n",
    "    # Change event name\n",
    "    row.event = \"cli:rrm\"\n",
    "    return row\n",
    "\n",
    "dfc = pd.concat([\n",
    "    dfc.loc[~(dfc.event == \"cli:rrm_in\")],\n",
    "    dfc[dfc.event == \"cli:rrm_in\"].apply(\n",
    "        parse_rrm_in, axis=1\n",
    "    ).explode(\"pod\")\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# ========= Parse GRS Output =========\n",
    "\n",
    "# This extracts from the `cli:grs_out` when a machine \n",
    "# was first recognized as running by Symphony.\n",
    "\n",
    "def parse_grs_out(row):\n",
    "    # Extract pods which are running\n",
    "\n",
    "    machines = [\n",
    "        machine \n",
    "        for request in row.detail[\"payload\"][\"requests\"]\n",
    "        for machine in request[\"machines\"]\n",
    "    ]\n",
    "\n",
    "    # if len(machines) == 0:\n",
    "    #     return None\n",
    "\n",
    "    row.pod = [\n",
    "        machine[\"name\"] for machine in machines\n",
    "    ]\n",
    "\n",
    "    row.detail = [\n",
    "        machine[\"status\"] for machine in machines\n",
    "    ]\n",
    "\n",
    "    row.event = [\n",
    "        f\"cli:grs_{machine[\"result\"]}\"  for machine in machines\n",
    "    ]\n",
    "\n",
    "    return row\n",
    "\n",
    "dfc = pd.concat([\n",
    "    dfc.loc[~(dfc.event == \"cli:grs_out\")],\n",
    "    dfc[dfc.event == \"cli:grs_out\"].apply(\n",
    "        parse_grs_out, axis=1\n",
    "    ).explode([\"pod\",\"detail\", \"event\"]),\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# ========= Load Cloud Hosts if existing =========\n",
    "\n",
    "if cloud_hosts is not None:\n",
    "    cloud_hosts = cloud_hosts_df.copy(deep=True)\n",
    "    cloud_hosts=cloud_hosts[[\n",
    "            \"hostname\", \"releaseTime\", \"launchTime\"\n",
    "    ]]\n",
    "    cloud_hosts.index.rename(\"pod\", inplace=True)\n",
    "    cloud_hosts.rename(\n",
    "        columns = {\n",
    "            \"launchTime\": \"hf:launched\",\n",
    "            \"releaseTime\": \"hf:released\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "\n",
    "# ========= Pivot table =========\n",
    "\n",
    "# This step pivots the table to have pods as indexes, events as columns\n",
    "# and values as time. \n",
    "\n",
    "dfc_pivot = dfc.pivot_table(\n",
    "    index=\"pod\",\n",
    "    columns=\"event\",\n",
    "    values=\"time\",\n",
    "    aggfunc=[\"first\", \"last\"]\n",
    ")\n",
    "\n",
    "preempted_pods = None\n",
    "dfc_pivot_preempted = None\n",
    "# Remove preempted pod lines\n",
    "if \"pod:node_preempted\" in dfc_pivot[\"first\"].columns:\n",
    "    preempted_pods = dfc_pivot[~dfc_pivot[\"first\"][\"pod:node_preempted\"].isna()].index\n",
    "    dfc_pivot_preempted = dfc_pivot.loc[preempted_pods]\n",
    "    dfc_pivot.drop(\n",
    "        index=preempted_pods,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "pod_schedule = dfc_pivot.copy(deep=True)\n",
    "\n",
    "# ========= Calculate deltas =========\n",
    "\n",
    "# Scaleup Delta\n",
    "pod_scale_up = pd.DataFrame()\n",
    "pod_scale_up[\"cli:rm->pod:create\"] = (dfc_pivot[\"first\"][\"pod:create\"] - dfc_pivot[\"first\"][\"cli:rm\"]).apply(lambda x: x.total_seconds())\n",
    "if cloud_hosts is not None:\n",
    "    pod_scale_up[\"hf:launched->pod:scheduled\"] = (dfc_pivot[\"last\"][\"pod:scheduled\"] - cloud_hosts[\"hf:launched\"]).apply(lambda x: x.total_seconds())\n",
    "pod_scale_up[\"pod:create->pod:scheduled\"] = (dfc_pivot[\"first\"][\"pod:scheduled\"] - dfc_pivot[\"first\"][\"pod:create\"]).apply(lambda x: x.total_seconds())\n",
    "# pod_scale_up[\"container:started->cli:grs_succeed\"] = (dfc_pivot[\"first\"][\"cli:grs_succeed\"] - dfc_pivot[\"first\"][\"container:started\"]).apply(lambda x: x.total_seconds())\n",
    "pod_scale_up[\"pod:create->cli:grs_executing\"] = (dfc_pivot[\"first\"][\"cli:grs_executing\"] - dfc_pivot[\"first\"][\"pod:create\"]).apply(lambda x: x.total_seconds())\n",
    "pod_scale_up[\"pod:schedule->cli:grs_succeed\"] = (dfc_pivot[\"first\"][\"cli:grs_succeed\"] - dfc_pivot[\"first\"][\"pod:scheduled\"]).apply(lambda x: x.total_seconds())\n",
    "\n",
    "# Scaledown Delta\n",
    "pod_scale_down = pd.DataFrame()\n",
    "pod_scale_down[\"cli:rrm->pod:delete\"] = (dfc_pivot[\"last\"][\"pod:delete\"] - dfc_pivot[\"first\"][\"cli:rrm\"]).apply(lambda x: x.total_seconds())\n",
    "\n",
    "if cloud_hosts is not None:\n",
    "    pod_scale_down[\"pod:delete->hf:released\"] = (dfc_pivot[\"last\"][\"pod:delete\"] - cloud_hosts[\"hf:released\"]).apply(lambda x: x.total_seconds())\n",
    "\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "\n",
    "if preempted_pods is not None:\n",
    "    print(f\"Number of preempted pods: {len(preempted_pods)}\")\n",
    "\n",
    "pod_scale_down = pod_scale_down.describe(\n",
    "    percentiles=[\n",
    "        0.25, 0.5, 0.75, 0.99\n",
    "    ]\n",
    ")\n",
    "\n",
    "pod_scale_up = pod_scale_up.describe(\n",
    "    percentiles=[\n",
    "        0.25, 0.5, 0.75, 0.99\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(pod_scale_down)\n",
    "pod_scale_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5479a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[\n",
    "    np.logical_and.reduce([\n",
    "        dfc.pod == \"g5c406243-248a-47c3-bd6b-52781a89237e-5ltnp-pod-785\",\n",
    "        # dfc.event==\"pod:delete\"\n",
    "    ])\n",
    "].set_index(\"time\").sort_index()\n",
    "\n",
    "2025-09-04T12:04:09+00:00\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033c5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc.event == \"pod:node_preempted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569fc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pod == \"g5c406243-248a-47c3-bd6b-52781a89237e-5ltnp-pod-1456\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b0051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc.pod == \"gb812e8c9-f2b4-4ab4-b356-e473ef841312-74wvg-pod-744\"].sort_values(by=\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13632675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.event.isin([\n",
    "    \"cli:grs_in\",\n",
    "    \"cli:grs_out\",\n",
    "    \"cli:grr_in\",\n",
    "    \"cli:grr_out\",\n",
    "    \"cli:rrm_in\",\n",
    "    \"cli:rrm_out\",\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacef84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.pod == \"gb812e8c9-f2b4-4ab4-b356-e473ef841312-74wvg-pod-744\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc.event == \"pod:delete\"].time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447156a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_not_removed, failed_grs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074dc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pods_not_removed = set(dfc.pod.unique()) - set(dfc[dfc.event == \"cli:rrm\"].pod.unique())\n",
    "failed_grs = dfc[dfc.event == \"cli:grs_fail\"].pod.dropna().unique()\n",
    "preempted_pods = dfc_pivot_preempted.index.to_list()\n",
    "\n",
    "set(failed_grs) - set(preempted_pods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed4b8d",
   "metadata": {},
   "source": [
    "# Pod Scale Up Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_scale_up_plot = pd.DataFrame()\n",
    "\n",
    "pod_scale_up_plot[\"cli:rm\"] = dfc_pivot[\"first\"][\"cli:rm\"]\n",
    "pod_scale_up_plot[\"pod:create\"] = dfc_pivot[\"first\"][\"pod:create\"]\n",
    "pod_scale_up_plot[\"cli:grs_executing\"] = dfc_pivot[\"first\"][\"cli:grs_executing\"]\n",
    "pod_scale_up_plot[\"pod:scheduled\"] = dfc_pivot[\"first\"][\"pod:scheduled\"]\n",
    "pod_scale_up_plot[\"cli:grs_succeed\"] = dfc_pivot[\"first\"][\"cli:grs_succeed\"]\n",
    "\n",
    "if cloud_hosts is not None:\n",
    "    pod_scale_up_plot[\"hf:launched\"] = cloud_hosts[\"hf:launched\"]\n",
    "\n",
    "pod_scale_up_plot = pod_scale_up_plot.melt().set_index(\"value\").sort_index().reset_index()\n",
    "pod_scale_up_plot[\"count\"] = pod_scale_up_plot.groupby(\"variable\").cumcount()\n",
    "scale_up_index = pod_scale_up_plot[\"value\"]\n",
    "\n",
    "pod_scale_up_plot = pod_scale_up_plot.pivot(\n",
    "    columns=\"variable\",\n",
    "    values=\"count\"\n",
    ")\n",
    "\n",
    "if REQUEST_TIMESTAMP is not None:\n",
    "    pod_scale_up_plot[\"time\"] = scale_up_index.apply(\n",
    "        lambda x: (x - REQUEST_TIMESTAMP).total_seconds()\n",
    "    )\n",
    "else:\n",
    "    pod_scale_up_plot[\"time\"] = scale_up_index\n",
    "\n",
    "pod_scale_up_plot = pod_scale_up_plot.set_index(\"time\")\n",
    "\n",
    "pod_scale_up_plot.head()\n",
    "\n",
    "\n",
    "# ============= Configure Plot =============\n",
    "\n",
    "# Reorder columns\n",
    "pod_scale_up_plot = pod_scale_up_plot[[\n",
    "    \"cli:rm\",\n",
    "    \"pod:create\",\n",
    "    \"cli:grs_executing\",\n",
    "    \"pod:scheduled\",\n",
    "    \"cli:grs_succeed\",\n",
    "    # \"hf:launched\"\n",
    "]]\n",
    "\n",
    "pod_scale_up_plot.rename(\n",
    "    columns={\n",
    "        \"cli:rm\": \"CLI Request Machine\",\n",
    "        \"pod:create\": \"Pod Created\",\n",
    "        \"cli:grs_executing\": \"CLI Get Request Status: Executing\",\n",
    "        \"pod:scheduled\": \"Pod Scheduled\",\n",
    "        \"cli:grs_succeed\": \"CLI Get Request Status: Succeded\",\n",
    "        # \"hf:launched\": \"Host Factory API Value: Launched\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "pod_scale_up_plot.columns.rename(\"Event Count\", inplace=True)\n",
    "\n",
    "if REQUEST_TIMESTAMP is not None:\n",
    "    pod_scale_up_plot.index.rename(\"Time after API request (seconds)\", inplace=True)\n",
    "else:\n",
    "    pod_scale_up_plot.index.rename(\"Timestamp\", inplace=True)\n",
    "\n",
    "pod_scale_up_fig = pod_scale_up_plot.plot(\n",
    "    kind=\"scatter\",\n",
    "    title=\"Pod Scale Up\"\n",
    ")\n",
    "\n",
    "pod_scale_up_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b2b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_scale_up_fig.write_image(\n",
    "    file=test_folder.joinpath(\"pod_scale_up.svg\"),\n",
    "    format=\"svg\",\n",
    "    width=900,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "pod_scale_up_fig.write_html(\n",
    "    file=test_folder.joinpath(\"pod_scale_up.html\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ed255",
   "metadata": {},
   "source": [
    "# Pod Scale Down Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b02e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pod_scale_down_plot = pd.DataFrame()\n",
    "pod_scale_down_plot[\"cli:rrm\"] = dfc_pivot[\"first\"][\"cli:rrm\"]\n",
    "pod_scale_down_plot[\"pod:delete\"] = dfc_pivot[\"last\"][\"pod:delete\"]\n",
    "\n",
    "if cloud_hosts is not None:\n",
    "    pod_scale_down_plot[\"hf:released\"] = cloud_hosts[\"hf:released\"]\n",
    "\n",
    "pod_scale_down_plot = pod_scale_down_plot.melt().set_index(\"value\").sort_index().reset_index()\n",
    "pod_scale_down_plot[\"count\"] = pod_scale_down_plot.groupby(\"variable\").cumcount()\n",
    "scale_down_index = pod_scale_down_plot[\"value\"]\n",
    "\n",
    "pod_scale_down_plot = pod_scale_down_plot.pivot(\n",
    "    columns=\"variable\",\n",
    "    values=\"count\"\n",
    ")\n",
    "\n",
    "if RETURN_TIMESTAMP is not None:\n",
    "    pod_scale_down_plot[\"time\"] = scale_down_index.apply(\n",
    "        lambda x: (x - RETURN_TIMESTAMP).total_seconds()\n",
    "    )\n",
    "else:\n",
    "    pod_scale_down_plot[\"time\"] = scale_down_index\n",
    "\n",
    "pod_scale_down_plot = pod_scale_down_plot.set_index(\"time\")\n",
    "\n",
    "\n",
    "# ============= Configure Plot =============\n",
    "\n",
    "# Reorder columns\n",
    "pod_scale_down_plot = pod_scale_down_plot[[\n",
    "    \"cli:rrm\",\n",
    "    # \"hf:released\",\n",
    "    \"pod:delete\",\n",
    "]]\n",
    "\n",
    "pod_scale_down_plot.columns.rename(\"Event Count\", inplace=True)\n",
    "\n",
    "pod_scale_down_plot.rename(\n",
    "    columns={\n",
    "        \"cli:rrm\": \"CLI Request Return Machines\",\n",
    "        \"hf:released\": \"Host Factory API Timestamp: Released\",\n",
    "        \"pod:delete\": \"Pod Deleted\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "if REQUEST_TIMESTAMP is not None:\n",
    "    pod_scale_down_plot.index.rename(\"Time after return API request (seconds)\", inplace=True)\n",
    "else:\n",
    "    pod_scale_down_plot.index.rename(\"Timestamp\", inplace=True)\n",
    "\n",
    "pod_scale_down_fig = pod_scale_down_plot.plot(\n",
    "    kind=\"scatter\",\n",
    "    title=\"Pod Scale Down\"\n",
    ")\n",
    "\n",
    "pod_scale_down_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0958b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_scale_down_fig.write_image(\n",
    "    file=test_folder.joinpath(\"pod_scale_down.svg\"),\n",
    "    format=\"svg\",\n",
    "    width=900,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "pod_scale_down_fig.write_html(\n",
    "    file=test_folder.joinpath(\"pod_scale_down.html\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e14c8e",
   "metadata": {},
   "source": [
    "# Node General Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42438c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfc = df.copy(deep=True)\n",
    "\n",
    "# Filter pertinent events\n",
    "dfc = dfc[\n",
    "    dfc.event.isin([\n",
    "            \"pod:scheduled\",\n",
    "            \"node:preempted\",\n",
    "            \"node:create\",\n",
    "            \"node:ready_patch\",\n",
    "            \"pod:delete\",\n",
    "            \"node:delete\",\n",
    "            \"pod:create\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "first_node_by_pod = dfc.pivot_table(\n",
    "    index=\"pod\",\n",
    "    values=\"node\",\n",
    "    aggfunc=\"first\"\n",
    ")[\"node\"]\n",
    "\n",
    "def backprogate_node_in_pod_creation(row):\n",
    "    row.node = first_node_by_pod.loc[row.pod]\n",
    "    return row\n",
    "\n",
    "dfc[dfc.event == \"pod:create\"] = dfc[dfc.event == \"pod:create\"].apply(backprogate_node_in_pod_creation, axis=1)\n",
    "\n",
    "dfc_first = dfc.pivot_table(\n",
    "    index=\"node\",\n",
    "    columns=\"event\",\n",
    "    values=\"time\",\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "\n",
    "dfc = dfc.pivot_table(\n",
    "    index=\"node\",\n",
    "    columns=\"event\",\n",
    "    values=\"time\",\n",
    "    aggfunc=\"last\"\n",
    ").drop(\n",
    "    columns=[\n",
    "        \"pod:scheduled\",\n",
    "    ]\n",
    ").join(dfc_first[[\"pod:scheduled\"]])\n",
    "\n",
    "\n",
    "first_pod_create_timestamp = dfc_pivot[\"first\"][\"pod:create\"].min()\n",
    "first_pod_delete_timestamp = dfc_pivot[\"last\"][\"pod:delete\"].min()\n",
    "\n",
    "# Removes nodes without pods\n",
    "nodes_without_pods = dfc[dfc[\"pod:scheduled\"].isna()].index\n",
    "dfc.drop(index=nodes_without_pods, inplace=True)\n",
    "\n",
    "# # Remove preempted nodes\n",
    "if \"node:preempted\" in dfc.columns:\n",
    "    preempted_nodes = dfc[~dfc[\"node:preempted\"].isna()].index\n",
    "    dfc.drop(index=preempted_nodes, inplace=True)\n",
    "\n",
    "# Calculate delta \n",
    "dfc[\"first-pod-create->node:create\"] = (\n",
    "    dfc[\"node:create\"] - first_pod_create_timestamp\n",
    ").apply(lambda x: x.total_seconds())\n",
    "\n",
    "dfc[\"pod:delete->node:delete\"] = (dfc[\"node:delete\"] - dfc[\"pod:delete\"]).apply(lambda x: x.total_seconds())\n",
    "\n",
    "\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(f\"Number of node create events: {(df.event == \"node:create\").sum()}\")\n",
    "print(f\"Number of node preemption events: {(df.event == \"node:preempted\").sum()}\")\n",
    "print(f\"Number of unique nodes preempted: {len(df[df.event == \"node:preempted\"].node.unique())}\")\n",
    "print(f\"Number of unique nodes: {len(df.node.dropna().unique())}\")\n",
    "print(f\"Number of nodes without pods scheduled: {len(nodes_without_pods)}\")\n",
    "\n",
    "dfc_desc = dfc.describe(\n",
    "    percentiles=[\n",
    "        0.25, 0.5, 0.77, 0.99\n",
    "    ]\n",
    ")\n",
    "\n",
    "dfc_desc\n",
    "\n",
    "# First (overall pod creation) \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbebcb0",
   "metadata": {},
   "source": [
    "# Node Scale Up Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_scale_up = dfc.copy(deep=True)\n",
    "\n",
    "node_scale_up = node_scale_up[[\n",
    "    \"node:create\",\n",
    "    # \"node:preempted\",\n",
    "    \"node:ready_patch\",\n",
    "    \"pod:scheduled\",\n",
    "    \"pod:create\"\n",
    "]]\n",
    "\n",
    "node_scale_up = node_scale_up.melt().set_index(\"value\").sort_index().reset_index()\n",
    "\n",
    "node_scale_up[\"count\"] = node_scale_up.groupby(\"event\").cumcount()\n",
    "\n",
    "node_scale_up_index = node_scale_up[\"value\"].apply(\n",
    "    lambda x:  (x - first_pod_create_timestamp).total_seconds()\n",
    ")\n",
    "\n",
    "node_scale_up = node_scale_up.pivot(\n",
    "    columns=\"event\",\n",
    "    values=\"count\"\n",
    ")\n",
    "\n",
    "node_scale_up[\"time\"] = node_scale_up_index\n",
    "node_scale_up = node_scale_up.set_index(\"time\")\n",
    "\n",
    "# =========== Format plot ===========\n",
    "\n",
    "node_scale_up.columns.rename(\"Event Count\", inplace=True)\n",
    "node_scale_up.index.rename(\"Time after first pod creation (seconds)\", inplace=True)\n",
    "\n",
    "node_scale_up.rename(\n",
    "    columns={\n",
    "        \"node:create\": \"Node Created\",\n",
    "        \"pod:scheduled\": \"First Pod Scheduled\",\n",
    "        \"pod:create\": \"First Pod Created\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "node_scale_up_fig = node_scale_up.plot(\n",
    "    kind=\"scatter\",\n",
    "    title=\"Node Scaleup\",\n",
    ")\n",
    "\n",
    "node_scale_up_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_scale_up_fig.write_image(\n",
    "    file=test_folder.joinpath(\"node_scale_up.svg\"),\n",
    "    format=\"svg\",\n",
    "    width=900,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "node_scale_up_fig.write_html(\n",
    "    test_folder.joinpath(\"node_scale_up.html\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552086b",
   "metadata": {},
   "source": [
    "# Node Scale Down Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3f4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_scale_down = dfc.copy(deep=True)\n",
    "\n",
    "node_scale_down = node_scale_down[[\n",
    "    \"pod:delete\",\n",
    "    \"node:delete\",\n",
    "    # \"node:preempted\"\n",
    "]]\n",
    "\n",
    "node_scale_down = node_scale_down.melt().set_index(\"value\").sort_index().reset_index()\n",
    "\n",
    "node_scale_down[\"count\"] = node_scale_down.groupby(\"event\").cumcount()\n",
    "\n",
    "node_scale_down.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_scale_down_index = node_scale_down[\"value\"].apply(\n",
    "    lambda x:  (x - first_pod_delete_timestamp).total_seconds()\n",
    ")\n",
    "\n",
    "node_scale_down = node_scale_down.pivot(\n",
    "    columns=\"event\",\n",
    "    values=\"count\"\n",
    ")\n",
    "\n",
    "node_scale_down[\"time\"] = node_scale_down_index\n",
    "node_scale_down = node_scale_down.set_index(\"time\")\n",
    "\n",
    "# =========== Format plot ===========\n",
    "\n",
    "node_scale_down.columns.rename(\"Event Count\", inplace=True)\n",
    "node_scale_down.index.rename(\"Time after first intentional pod deletion (seconds)\", inplace=True)\n",
    "\n",
    "node_scale_down = node_scale_down[[\n",
    "    \"pod:delete\",\n",
    "    \"node:delete\"\n",
    "]]\n",
    "\n",
    "node_scale_down.rename(\n",
    "    columns={\n",
    "        \"pod:delete\": \"Last pod deleted\",\n",
    "        \"node:delete\": \"Node deleted\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "node_scale_down_fig = node_scale_down.plot(\n",
    "    kind=\"scatter\",\n",
    "    title=\"Node Scaledown\",\n",
    ")\n",
    "\n",
    "node_scale_down_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c84693",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_scale_down_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.to_csv(\n",
    "    test_folder.joinpath(\"node_timing.csv\")\n",
    ")\n",
    "\n",
    "dfc_desc.to_csv(\n",
    "    test_folder.joinpath(\"node_timing_description.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[\"first-pod-create->node:create\"].apply(\n",
    "    lambda x: x.total_seconds()\n",
    ").hist(\n",
    "    nbins=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a single pod per node, extract pod associated to node and pivot table \n",
    "# To index = pod, rows = time, columns = events \n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "# Extract pod name from pod:scheduled for node:ready\n",
    "dfc.loc[dfc.event == \"node:ready\",\"pod\"] = dfc[dfc.event == \"node:ready\"].apply(\n",
    "    lambda row: \n",
    "        dfc[np.logical_and(dfc.event == \"pod:scheduled\", dfc.node == row.node)].iloc[0].pod,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Pivot table to time \n",
    "dfc = dfc[\n",
    "    [\"time\", \"event\", \"pod\"]\n",
    "][\n",
    "    dfc.event.isin([\"pod:create\", \"container:started\", \"pod:scheduled\", \"node:ready\"])\n",
    "].pivot_table(\n",
    "    index=\"pod\",\n",
    "    columns=[\"event\"],\n",
    "    values=[\"time\"],\n",
    "    # Aggregate by first and last apperances\n",
    "    aggfunc=[\"first\", \"last\"]\n",
    ")\n",
    "\n",
    "# Use only the first time appearance\n",
    "results = dfc[\"first\"][\"time\"]\n",
    "\n",
    "results[\"create->start\"] = results[\"container:started\"] - results[\"pod:create\"]\n",
    "results[\"create->scheduled\"] = results[\"pod:scheduled\"] - results[\"pod:create\"]\n",
    "results[\"scheduled->started\"] = results[\"container:started\"] - results[\"pod:scheduled\"]\n",
    "results[\"create->node_ready\"] = results[\"node:ready\"] - results[\"pod:create\"]\n",
    "results[\"node_ready->started\"] = results[\"container:started\"] - results[\"node:ready\"]\n",
    "\n",
    "print(f\"Run: {RUN_ID}\")\n",
    "results.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply multiple filters to better visualize data...\n",
    "# This example requires the pre creation of grr shift \n",
    "\n",
    "df[\n",
    "    np.logical_or.reduce([\n",
    "        df.event.isin([\"node:preempted\", \"pod:delete\",\"node:deleted\",\"node:ready\",\"cli:grs_in\", \"cli:grs_out\",\"cli:rrm_in\", \"cli:rrm_out\"]),\n",
    "        df.grr_shift_out == True,\n",
    "        df.grr_shift_in == True\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query specific pod timeline\n",
    "\n",
    "POD = \"gf813d2c6-cfd2-4aee-b035-4ffeb67a4af0-cg8tw-pod-1\"\n",
    "NODE = \"gke-cluster-test-0-n2-node-pool-test--1487096a-d446\"\n",
    "ACN = \"gf813d2c6-cfd2-4aee-b035-4ffeb67a4af0-cg8tw\"\n",
    "\n",
    "df[\n",
    "    np.logical_or(\n",
    "        df.node == NODE,\n",
    "        df.pod == POD,\n",
    "        df.acn == ACN\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as excel\n",
    "# (requires removing TZ info)\n",
    "\n",
    "dfc = df.copy()\n",
    "dfc.time = dfc.time.apply(lambda x: x.replace(tzinfo=None))\n",
    "dfc.set_index(\"time\").sort_index().to_excel(\"base-test-7.xlsx\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
